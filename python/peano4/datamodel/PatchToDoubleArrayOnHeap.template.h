//
// Peano4 data file
// Generated by Peano's Python API
// www.peano-framework.org
// This is generated. Be careful with adding your own stuff
//
#pragma once



#include <string>
#include <memory>


#include "tarch/la/Vector.h"
#include "tarch/mpi/mpi.h"

#include "peano4/utils/Globals.h"
#include "peano4/grid/LoadStoreComputeFlag.h"

#include "peano4/datamanagement/CellMarker.h"
#include "peano4/datamanagement/FaceMarker.h"
#include "peano4/datamanagement/VertexMarker.h"
#include "peano4/grid/TraversalObserver.h"


{% for item in NAMESPACE -%}
  namespace {{ item }} {
{%- endfor %}

  class {{CLASSNAME}};

{% for item in NAMESPACE -%}
  }
{%- endfor %}


{{INCLUDES}}



struct {{NAMESPACE | join("::")}}::{{CLASSNAME}} {
  private:
    #if Parallel
    static MPI_Datatype   Datatype;
    #endif

    #if PeanoDebug>=1
    tarch::la::Vector<Dimensions,double> _debugX;
    tarch::la::Vector<Dimensions,double> _debugH;
    #endif

  public:
    typedef {{FLOAT_TYPE}} DoFType;

    #if Dimensions==2
    static constexpr int Cardinality = {{CARDINALITY_2D}};
    #else
    static constexpr int Cardinality = {{CARDINALITY_3D}};
    #endif

    #if PeanoDebug>=1
    void setDebugX( const tarch::la::Vector<Dimensions,double>& data );
    void setDebugH( const tarch::la::Vector<Dimensions,double>& data );
    tarch::la::Vector<Dimensions,double> getDebugX() const;
    tarch::la::Vector<Dimensions,double> getDebugH() const;
    #endif
  
    /**
     * Actual data as stored on the heap. As we work with a pointer,
     * we have to carefully define constructors, copy constructors, copy
     * operators and the destructor.
     */
    {{FLOAT_TYPE}}*   value;

    enum ObjectConstruction {
      NoData
    };


    /**
     * Create new instance
     *
     * The routine allocates new data on the heap via tarch::allocateMemory()
     * and stores the outcome within the value pointer.
     */
    {{CLASSNAME}}();

    {{CLASSNAME}}(ObjectConstruction flag);

    /**
     * Deep copy
     *
     * We allocate new data within value and then invoke clone() to actually
     * copy the content of the heaps from other over into this new data field.
     */
    {{CLASSNAME}}(const {{CLASSNAME}}& other);

    /**
     * Destructor
     *
     * Free memory allocated in the two constructors.
     */
    ~{{CLASSNAME}}();

    /**
     * Clone content. Assume other and present class have their own smart pointer
     *
     * This routine is used by the deep copies of the stack. It is also used by
     * the copy constructor and the assignment operator.
     */
    void clone(const {{CLASSNAME}}& other);

    /**
     * Delegate to clone().
     */
    {{CLASSNAME}}& operator=(const {{CLASSNAME}}& other);

    std::string toString() const;

    {% if DATA_ASSOCIATION == 1 -%}
    void merge(peano4::grid::TraversalObserver::SendReceiveContext context, const {{CLASSNAME}}& neighbour, const peano4::datamanagement::VertexMarker& marker, int spacetreeId);
    bool send(
      const peano4::datamanagement::VertexMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    ) const;
    bool receiveAndMerge(
      const peano4::datamanagement::VertexMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    ) const;
    static ::peano4::grid::LoadStoreComputeFlag loadStoreComputeFlag(
      const peano4::datamanagement::VertexMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    );
    {% endif -%}
  
    {% if DATA_ASSOCIATION == 2 -%}
    void merge(peano4::grid::TraversalObserver::SendReceiveContext context, const {{CLASSNAME}}& neighbour, const peano4::datamanagement::FaceMarker& marker, int spacetreeId);
    bool send(
      const peano4::datamanagement::FaceMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    ) const;
    bool receiveAndMerge(
      const peano4::datamanagement::FaceMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    ) const;
    static ::peano4::grid::LoadStoreComputeFlag loadStoreComputeFlag(
      const peano4::datamanagement::FaceMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    );
    {% endif -%}
  
    {% if DATA_ASSOCIATION == 3 -%}
    void merge(peano4::grid::TraversalObserver::SendReceiveContext context, const {{CLASSNAME}}& neighbour, const peano4::datamanagement::CellMarker& marker, int spacetreeId);
    bool send(
      const peano4::datamanagement::CellMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    ) const;
    bool receiveAndMerge(
      const peano4::datamanagement::CellMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    ) const;
    static ::peano4::grid::LoadStoreComputeFlag loadStoreComputeFlag(
      const peano4::datamanagement::CellMarker& marker
      {% for arg in ADDITIONAL_LOAD_STORE_ARGUMENTS %}, const {{arg[1]}}& {{arg[2]}} {% endfor %}
    );
    {% endif -%}

  
  
    #ifdef Parallel
    /**
     * Initialises the MPI datatype.
     */
    static void initDatatype();
  
    /**
     * Free MPI datatype.
     */
    static void shutdownDatatype();

    /**
     * Different to the vanilla version of the patch to double mapping, the datatype here
     * does never (!) include any meta data.
     */
    static MPI_Datatype  getForkDatatype();
    static MPI_Datatype  getJoinDatatype();
    static MPI_Datatype  getBoundaryExchangeDatatype();
    static MPI_Datatype  getMultiscaleDataExchangeDatatype();
    static MPI_Datatype  getGlobalCommunciationDatatype();
    #endif
};


