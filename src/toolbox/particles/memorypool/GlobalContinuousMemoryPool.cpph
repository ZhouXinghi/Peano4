#include "GlobalContinuousMemoryPool.h"

#include "tarch/accelerator/accelerator.h"

#include "tarch/multicore/Lock.h"


template <class T>
tarch::logging::Log  toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::_log( "toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>" );


template <class T>
typename toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::GlobalMemory  toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::_globalMemory(0);


template <class T>
toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::GlobalContinuousMemoryPool():
  _gatheredDataPointer(nullptr),
  _globalMemoryPage(UndefinedMemoryPage) {
}


template <class T>
void toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::scatter() {
  if (_gatheredDataPointer!=nullptr and not container.empty()) {
    logDebug( "scatter()", "scatter " << container.size() << " element(s) from heap" );

    const int oldSize = container.size();
    container.clear();
    for (int i=0; i<oldSize; i++) {
      container.push_back( new T( _gatheredDataPointer[i]) );
    }

    tarch::freeMemory( _gatheredDataPointer, tarch::MemoryLocation::Heap );
    _gatheredDataPointer = nullptr;
  }
  else if (_globalMemoryPage!=UndefinedMemoryPage and not container.empty()) {
    logDebug( "scatter()", "scatter " << container.size() << " element(s) from large continuous memory" );
    assertion1( _globalMemory.pages[ _globalMemoryPage ].used, _globalMemoryPage );

    const int size  = _globalMemory.pages[ _globalMemoryPage ].size;
    const int first = _globalMemory.pages[ _globalMemoryPage ].startIndex;

    logDebug( "scatter()", "page size is " << size << " starting at index " << first );

    container.clear();
    for (int i=0; i<size; i++) {
      container.push_back( new T( _globalMemory.data[ first+i ] ) );
    }

    _globalMemory.freePage( _globalMemoryPage );
    _globalMemoryPage = UndefinedMemoryPage;
  }
}


template <class T>
void toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::clearAndReset() {
  container.clear();
  _gatheredDataPointer = nullptr;
  _globalMemoryPage    = UndefinedMemoryPage;
}


template <class T>
typename toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::Container::iterator
toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::scatterAndUpdateIterator( const typename Container::iterator&  p ) {
  assertion( not container.empty() or not isGathered() );
  if (not isGathered()) {
    return p;
  }
  else if (_gatheredDataPointer!=nullptr) {
    logDebug( "scatterAndUpdateIterator()", "scatter " << container.size() << " element(s) currently held on heap" );

    Container newContainer;
    typename Container::iterator result;

    for (auto oldContainerIterator: container) {
      newContainer.push_back( new T(*oldContainerIterator) );
      if (oldContainerIterator==*p) {
        result = newContainer.end();
        result--;
      }
    }

    container.clear();
    container.splice( container.begin(), newContainer );

    tarch::freeMemory( _gatheredDataPointer, tarch::MemoryLocation::Heap );
    _gatheredDataPointer = nullptr;

    return result;
  }
  else {
    logDebug( "scatterAndUpdateIterator()", "scatter " << container.size() << " element(s) currently held within page of continuous memory" );

    Container newContainer;
    typename Container::iterator result;

    for (auto oldContainerIterator: container) {
      newContainer.push_back( new T(*oldContainerIterator) );
      if (oldContainerIterator==*p) {
        result = newContainer.end();
        result--;
      }
    }

    container.clear();
    container.splice( container.begin(), newContainer );

    _globalMemory.freePage(_globalMemoryPage);
    _globalMemoryPage = UndefinedMemoryPage;

    return result;
  }
}


template <class T>
void toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::gather() {
  assertion( not container.empty() or not isGathered() );
  if ( not isGathered() and not container.empty()) {
    logDebug( "gather()", "gather " << container.size() << " element(s)" );
    
    _globalMemoryPage = _globalMemory.addPage( container.size() );

    if ( _globalMemoryPage==UndefinedMemoryPage) {
      logDebug( "gather()", "have not been able to book page in continuous memory, so gather " << container.size() << " element(s) on heap" );
      _gatheredDataPointer = tarch::allocateMemory<T>( container.size(), tarch::MemoryLocation::Heap );
      int entry = 0;
      for (auto& p: container) {
        _gatheredDataPointer[entry] = *p;
        delete p;
        entry++;
      }

      typename Container::iterator p = container.begin();
      for (int entry=0; entry<container.size(); entry++) {
        *p = _gatheredDataPointer + entry;
        p++;
      }
    }
    else {
      logDebug( "gather()", "gather " << container.size() << " element(s) into page " << _globalMemoryPage );

      const int first = _globalMemory.pages[ _globalMemoryPage ].startIndex;

      int entry = 0;
      for (auto& p: container) {
        _globalMemory.data[first+entry] = *p;
        delete p;
        entry++;
      }

      typename Container::iterator p = container.begin();
      for (int entry=0; entry<container.size(); entry++) {
        assertion( first+entry<_globalMemory.data.size() );
        *p = &( _globalMemory.data[first+entry] );
        p++;
      }
    }    
  }
}


template <class T>
bool toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::isGathered() const {
  assertion( not( _gatheredDataPointer!=nullptr and _globalMemoryPage!=UndefinedMemoryPage ));
  return _gatheredDataPointer!=nullptr or _globalMemoryPage!=UndefinedMemoryPage;
}


template <class T>
void toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::replace( typename Container::iterator p, T* newCopy ) {
  assertion( not container.empty() or _gatheredDataPointer==nullptr );
  if ( isGathered() ) {
    (**p) = *newCopy;
    delete newCopy;
  }
  else {
    container.erase(p);
    container.push_back(newCopy);
  }
}


template <class T>
toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::GlobalMemory::GlobalMemory( int initialCapacity ):
  data(initialCapacity),
  pages(),
  additionalEntriesRequested(0) {
}


template <class T>
int toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::GlobalMemory::addPage( int size ) {
  logTraceInWith1Argument( "addPage(int)", size );

  assertion(size>0);

  tarch::multicore::Lock lock( semaphore );

  int freePage    = UndefinedMemoryPage;
  int currentPage = 0;
  while (currentPage<pages.size() and freePage!=UndefinedMemoryPage) {
    if ( not pages[currentPage].used and pages[currentPage].size==size ) {
      freePage = currentPage;
    }
    currentPage++;
  }

  if ( freePage==UndefinedMemoryPage and totalUsedSize()==0 and size>data.size() ) {
    logInfo( "addPage(int)", "global memory seems not to be used at all, but is to small to accommodate first page of size " << size << ". Increase capacity to be able accommodate page" );
    data.resize( size );
  }

  if ( freePage==UndefinedMemoryPage and totalUsedSize()+size<=data.size() ) {
    logDebug(
      "addPage(int)", "global memory had no free page of size " << size <<
      ". Add new page, as capacity is available (used size=" << totalUsedSize() << " vs capacity=" <<
      data.size() << ")"
    );
    Page newPage;
    newPage.startIndex = totalUsedSize();
    newPage.size       = size;
    newPage.used       = true;

    pages.push_back( newPage );

    freePage = pages.size()-1;
  }
  else {
    if (additionalEntriesRequested==0) {
      logInfo(
        "addPage(int)",
        "global memory had no free page of size " << size << " and we cannot accommodate an additional page of size " <<
        size << " (currently used size=" << totalUsedSize() << " vs available capacity of " <<
        data.size() << "). Will not report on further requests unless global memory space has grown"
      );
    }
    additionalEntriesRequested += size;
    logDebug( "addPage(int)", "additional-entries-requested=" << additionalEntriesRequested );
  }

  logTraceOutWith1Argument( "addPage(int)", freePage );
  return freePage;
}


template <class T>
bool toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::requestCompleteScatter() {
    // @todo Oder true?
  return _globalMemory.additionalEntriesRequested>0;
}


template <class T>
void toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::GlobalMemory::freePage( int pageNumber ) {
  assertion1( pageNumber>=0, pageNumber );
  assertion1( pageNumber<pages.size(), pageNumber );

  tarch::multicore::Lock lock( semaphore );

  pages[pageNumber].used = false;

  while ( not pages.empty() and not pages[pages.size()-1].used ) {
    pages.pop_back();
  }

  if (pages.empty() and additionalEntriesRequested>0) {
    logInfo(
      "freePage(int)",
      "global memory is completely empty, so use opportunity to increase total size from " <<
      data.size() << " to " << ( data.size() + additionalEntriesRequested )
    );
    assertion3( data.size() + additionalEntriesRequested <= data.max_size(), data.size(), additionalEntriesRequested, data.max_size() );
    data.resize( data.size() + additionalEntriesRequested );
    additionalEntriesRequested = 0;
  }
}


template <class T>
int toolbox::particles::memorypool::GlobalContinuousMemoryPool<T>::GlobalMemory::totalUsedSize() const {
  return pages.empty()
       ? 0
       : pages[pages.size()-1].startIndex + pages[pages.size()-1].size;
}

